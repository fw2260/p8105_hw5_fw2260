---
title: "Homework 5"
author: "Lily Wang"
date: "11/10/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

The homicide dataset contains information gathered by the *Washington Post* on homicides in 50 major US cities. The dataset contains information such as the victim's name, age, race, sex, location, and whether or not an arrest was made.

Reading and cleaning the homicide data:

```{r clean_homicides, message = FALSE}
homicide_df <-
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved",
      disposition == "Open/No arrest" ~ "unsolved")
    ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

Get total unsolved homicides and total homicides for each city, then perform prop test on Baltimore, MD:

```{r baltimore}
aggregate_df <- homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )

prop.test(aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
          aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Iterate through all the cities:

```{r all_cities}
results_df <- aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

Make a plot to display the proportion of unsolved homicides (+- confidence interval) in all the cities from lowest to highest:

```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


## Problem 2

Read in all csv's and tidying the result to include an `id` and `arm` variable:

```{r clean_longitudinal, message = FALSE}
longitudinal_df <- 
  tibble(
    path = list.files("longitudinal_data")) %>% 
  mutate(path = str_c("longitudinal_data/", path),
         data = map(.x = path, ~read_csv(.x))) %>% 
  unnest(data) %>% 
  mutate(id = str_extract(path, "\\d+"),
         id = as.numeric(id),
         arm = str_extract(path, "con|exp")) %>% 
  relocate(id, arm, path,everything()) %>% 
  mutate(arm = recode(arm, con = "control", exp = "experimental")) %>% 
  pivot_longer(week_1:week_8,
               names_to = "week",
               names_prefix = "week_",
               values_to = "value")
```

Make a spaghetti plot to display the results over time for each subject:

```{r spaghetti_plot}
longitudinal_df %>% 
  ggplot(aes(x = week, y = value, group = id, color = arm)) +
  geom_path()
```

The control group seemed to stay pretty consistent (if not slightly decrease) in their values over the 8 weeks, while the experimental group's values seemed to increase over the 8 weeks.


## Problem 3

Generate 5000 datasets with n = 30, mu = 0, and sigma = 5, then extract their means and p-values:

```{r mu_0}
set.seed(3)

sim_mean_t <- function(n = 30, mu, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n = n, mean = mu, sd = sigma))
  
  sim_data %>% 
    summarize(mu_hat = mean(x),
              p_value = t.test(x) %>% broom::tidy() %>% pull(p.value))
}

sim_results <-
  rerun(50, sim_mean_t(mu = 0)) %>% 
  bind_rows()
```

Repeat this for mu = {1,2,3,4,5,6}:

```{r mu_1_6}

```


